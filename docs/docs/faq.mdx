---
sidebar_position: 101
id: "faq"
title: "FAQ"
---

# FAQ

### How do I set up my own LLM?

Open your [config file](./config) in Wave using `wsh editconfig` (the config file is normally located
at `~/.config/waveterm/settings.json`).

| Key Name     | Type   | Function                                        |
| ------------ | ------ | ----------------------------------------------- |
| ai:baseurl   | string | Set the AI Base Url (must be OpenAI compatible) |
| ai:apitoken  | string | your AI api token                               |
| ai:name      | string | string to display in the Wave AI block header   |
| ai:model     | string | model name to pass to API                       |
| ai:maxtokens | int    | max tokens to pass to API                       |
| ai:timeoutms | int    | timeout (in milliseconds) for AI calls          |

Here's an example of pointing it to a local Ollama instance. Note that to get the text in the header of the AI block
to update, you'll need to set the "ai:name" key. For ollama, you'll also need to provide something for the
apitoken (even though it is ignored).

Here are the ollma open AI compatibility docs: https://github.com/ollama/ollama/blob/main/docs/openai.md

```json
{
  "ai:*": true,
  "ai:baseurl": "http://localhost:11434/v1",
  "ai:name": "llama3.2",
  "ai:model": "llama3.2",
  "ai:apitoken": "ollama"
}
```

Note: we set the `ai:*` key to true to clear all the existing "ai" keys so this config is a clean slate.

To switch between multiple models, consider [adding AI Presets](./presets) instead.

### How can I connect to Azure AI?

Open your [config file](./config) in Wave using `wsh editconfig` (the config file is normally located
at `~/.config/waveterm/settings.json`).

You'll need to set your `ai:baseurl` to your Azure AI Base URL (do not include query parameters or `api-version`).
You'll also need to set `ai:apitype` to `azure`. You can then set the `ai:model`, and `ai:apitoken` appropriately
for your setup.

### How can I connect to Claude?

Open your [config file](./config) in Wave using `wsh editconfig`.

Set these keys:

```json
{
  "ai:*": true,
  "ai:apitype": "anthropic",
  "ai:model": "claude-3-5-sonnet-latest",
  "ai:apitoken": "<your anthropic API key>"
}
```

Note: we set the `ai:*` key to true to clear all the existing "ai" keys so this config is a clean slate.

### How can I connect to Perplexity?

Open your [config file](./config) in Wave using `wsh editconfig`.

Set these keys:

```json
{
  "ai:*": true,
  "ai:apitype": "perplexity",
  "ai:model": "llama-3.1-sonar-small-128k-online",
  "ai:apitoken": "<your perplexity API key>"
}
```

Note: we set the `ai:*` key to true to clear all the existing "ai" keys so this config is a clean slate.

To switch between models, consider [adding AI Presets](./presets) instead.

### How can I see the block numbers?

The block numbers will appear when you hold down Ctrl-Shift (and disappear once you release the key combo).

### How do I make a remote connection?

There is a button in the header. Click the <i className="fa-sharp fa-laptop"/> or <i className="fa-sharp fa-arrow-right-arrow-left"/>
and type the `[user]@[host]` that you wish to connect to.

### On Windows, how can I use Git Bash as my default shell?

In order to make Git Bash your default shell you'll need to set the configuration variable `term:localshellpath` to
the location of the Git Bash "bash.exe" binary. By default it is located at "C:\Program Files\Git\bin\bash.exe".
Just remember in JSON, backslashes need to be escaped. So add this to your [settings.json](./config) file:

```json
    "term:localshellpath": "C:\\Program Files\\Git\\bin\\bash.exe"
```
